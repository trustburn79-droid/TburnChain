/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * TBURN ENTERPRISE DATABASE MIGRATION TOOLKIT
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * 
 * ê°œë°œ DBì—ì„œ í”„ë¡œë•ì…˜ DBë¡œ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ë„êµ¬
 * 
 * ê¸°ëŠ¥:
 * - í…Œì´ë¸”ë³„ ì¦ë¶„ ë§ˆì´ê·¸ë ˆì´ì…˜
 * - ì§„í–‰ë¥  ì¶”ì  ë° ë¡œê¹…
 * - ë¡¤ë°± ì§€ì›
 * - ë¬´ê²°ì„± ê²€ì¦
 * 
 * ì‚¬ìš©ë²•:
 * 1. DATABASE_URL_PROD í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
 * 2. MIGRATION_MODE=true ì„¤ì •
 * 3. tsx server/db-migration.ts ì‹¤í–‰
 * 
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */

import { Pool, neonConfig } from "@neondatabase/serverless";
import ws from "ws";

neonConfig.webSocketConstructor = ws as any;

interface MigrationConfig {
  sourceUrl: string;      // ê°œë°œ DB URL
  targetUrl: string;      // í”„ë¡œë•ì…˜ DB URL
  tables: string[];       // ë§ˆì´ê·¸ë ˆì´ì…˜í•  í…Œì´ë¸” ëª©ë¡
  batchSize: number;      // ë°°ì¹˜ í¬ê¸°
  dryRun: boolean;        // í…ŒìŠ¤íŠ¸ ëª¨ë“œ
}

interface MigrationResult {
  table: string;
  rowsCopied: number;
  duration: number;
  success: boolean;
  error?: string;
}

interface MigrationReport {
  startTime: Date;
  endTime: Date;
  totalDuration: number;
  results: MigrationResult[];
  summary: {
    totalTables: number;
    successfulTables: number;
    failedTables: number;
    totalRowsCopied: number;
  };
}

// í•µì‹¬ í…Œì´ë¸” ëª©ë¡ (ì˜ì¡´ì„± ìˆœì„œëŒ€ë¡œ)
const CORE_TABLES = [
  // ê¸°ë³¸ í…Œì´ë¸” (ì™¸ë˜ í‚¤ ì—†ìŒ)
  'users',
  'wallets',
  'sessions',
  
  // ë¸”ë¡ì²´ì¸ í•µì‹¬ í…Œì´ë¸”
  'blocks',
  'transactions',
  'validators',
  'shards',
  'shard_config',
  
  // ê±°ë²„ë„ŒìŠ¤/ìŠ¤í…Œì´í‚¹
  'proposals',
  'votes',
  'staking_pools',
  'staking_positions',
  'staking_rewards',
  
  // DeFi
  'dex_pools',
  'dex_transactions',
  'lending_markets',
  'lending_positions',
  'yield_vaults',
  'yield_positions',
  
  // NFT/GameFi
  'nft_collections',
  'nft_items',
  'nft_listings',
  'gamefi_projects',
  'gamefi_tournaments',
  
  // í† í° ê´€ë ¨
  'token_standards',
  'token_registry',
  'token_distributions',
  
  // ì»¤ë®¤ë‹ˆí‹°
  'community_posts',
  'community_likes',
  'referrals',
  'newsletters',
  
  // íšŒì› ê´€ë¦¬ (Members)
  'members',
  'member_profiles',
  'member_staking_positions',
  'member_governance_profiles',
  'member_financial_profiles',
  'member_security_profiles',
  'member_performance_metrics',
  'member_slash_events',
  'member_audit_logs',
  'member_documents',
  'member_notes',
  
  // ì‹œìŠ¤í…œ
  'api_metrics',
  'api_hourly_stats',
  'api_daily_stats',
  'endpoint_metrics',
];

class EnterpriseDbMigrator {
  private sourcePool: Pool | null = null;
  private targetPool: Pool | null = null;
  private config: MigrationConfig;
  private aborted = false;

  constructor(config: MigrationConfig) {
    this.config = config;
  }

  async initialize(): Promise<void> {
    console.log('[Migration] ğŸ”§ Initializing database connections...');
    
    this.sourcePool = new Pool({
      connectionString: this.config.sourceUrl,
      max: 5,
      connectionTimeoutMillis: 10000,
    });

    this.targetPool = new Pool({
      connectionString: this.config.targetUrl,
      max: 5,
      connectionTimeoutMillis: 10000,
    });

    // ì—°ê²° í…ŒìŠ¤íŠ¸
    await this.sourcePool.query('SELECT 1');
    console.log('[Migration] âœ… Source database connected');
    
    await this.targetPool.query('SELECT 1');
    console.log('[Migration] âœ… Target database connected');
  }

  async getTableRowCount(pool: Pool, table: string): Promise<number> {
    try {
      const result = await pool.query(`SELECT COUNT(*) as count FROM "${table}"`);
      return parseInt(result.rows[0].count, 10);
    } catch {
      return 0;
    }
  }

  async tableExists(pool: Pool, table: string): Promise<boolean> {
    try {
      const result = await pool.query(`
        SELECT EXISTS (
          SELECT FROM information_schema.tables 
          WHERE table_schema = 'public' 
          AND table_name = $1
        )
      `, [table]);
      return result.rows[0].exists;
    } catch {
      return false;
    }
  }

  async migrateTable(table: string): Promise<MigrationResult> {
    const startTime = Date.now();
    let rowsCopied = 0;

    try {
      if (!this.sourcePool || !this.targetPool) {
        throw new Error('Database pools not initialized');
      }

      // ì†ŒìŠ¤ í…Œì´ë¸” ì¡´ì¬ í™•ì¸
      const sourceExists = await this.tableExists(this.sourcePool, table);
      if (!sourceExists) {
        console.log(`[Migration] â­ï¸ Skipping ${table} (not found in source)`);
        return {
          table,
          rowsCopied: 0,
          duration: Date.now() - startTime,
          success: true,
          error: 'Table not found in source'
        };
      }

      // íƒ€ê²Ÿ í…Œì´ë¸” ì¡´ì¬ í™•ì¸
      const targetExists = await this.tableExists(this.targetPool, table);
      if (!targetExists) {
        console.log(`[Migration] â­ï¸ Skipping ${table} (not found in target - run drizzle push first)`);
        return {
          table,
          rowsCopied: 0,
          duration: Date.now() - startTime,
          success: true,
          error: 'Table not found in target'
        };
      }

      const sourceCount = await this.getTableRowCount(this.sourcePool, table);
      console.log(`[Migration] ğŸ“Š ${table}: ${sourceCount} rows to migrate`);

      if (sourceCount === 0) {
        return {
          table,
          rowsCopied: 0,
          duration: Date.now() - startTime,
          success: true
        };
      }

      if (this.config.dryRun) {
        console.log(`[Migration] ğŸ” DRY RUN: Would migrate ${sourceCount} rows from ${table}`);
        return {
          table,
          rowsCopied: sourceCount,
          duration: Date.now() - startTime,
          success: true
        };
      }

      // ì»¬ëŸ¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
      const columnsResult = await this.sourcePool.query(`
        SELECT column_name 
        FROM information_schema.columns 
        WHERE table_name = $1 AND table_schema = 'public'
        ORDER BY ordinal_position
      `, [table]);
      
      const columns = columnsResult.rows.map(r => r.column_name);
      const columnList = columns.map(c => `"${c}"`).join(', ');
      
      // â˜… [2026-01-11] ê¸°ë³¸ í‚¤ ì»¬ëŸ¼ ì°¾ê¸° (ì•ˆì •ì ì¸ ì •ë ¬ì„ ìœ„í•´)
      const pkResult = await this.sourcePool.query(`
        SELECT a.attname
        FROM pg_index i
        JOIN pg_attribute a ON a.attrelid = i.indrelid AND a.attnum = ANY(i.indkey)
        WHERE i.indrelid = $1::regclass AND i.indisprimary
        ORDER BY array_position(i.indkey, a.attnum)
      `, [table]);
      
      // ê¸°ë³¸ í‚¤ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ctid ì‚¬ìš© (PostgreSQL ì‹œìŠ¤í…œ ì»¬ëŸ¼)
      const orderColumn = pkResult.rows.length > 0 
        ? pkResult.rows.map(r => `"${r.attname}"`).join(', ')
        : 'ctid';

      // ë°°ì¹˜ ë§ˆì´ê·¸ë ˆì´ì…˜ (ì•ˆì •ì ì¸ ì •ë ¬ ì‚¬ìš©)
      let offset = 0;
      while (offset < sourceCount && !this.aborted) {
        const batchResult = await this.sourcePool.query(`
          SELECT ${columnList} FROM "${table}" 
          ORDER BY ${orderColumn}
          LIMIT $1 OFFSET $2
        `, [this.config.batchSize, offset]);

        if (batchResult.rows.length === 0) break;

        // ë°°ì¹˜ ì‚½ì…
        for (const row of batchResult.rows) {
          const values = columns.map(c => row[c]);
          const placeholders = columns.map((_, i) => `$${i + 1}`).join(', ');
          
          try {
            await this.targetPool.query(`
              INSERT INTO "${table}" (${columnList}) 
              VALUES (${placeholders})
              ON CONFLICT DO NOTHING
            `, values);
            rowsCopied++;
          } catch (err: any) {
            // ì¤‘ë³µ í‚¤ ì˜¤ë¥˜ ë¬´ì‹œ
            if (!err.message?.includes('duplicate key')) {
              throw err;
            }
          }
        }

        offset += this.config.batchSize;
        const progress = Math.min(100, Math.round((offset / sourceCount) * 100));
        process.stdout.write(`\r[Migration] ğŸ“¥ ${table}: ${progress}% (${rowsCopied}/${sourceCount})`);
      }

      console.log(`\n[Migration] âœ… ${table}: Migrated ${rowsCopied} rows`);

      return {
        table,
        rowsCopied,
        duration: Date.now() - startTime,
        success: true
      };
    } catch (error: any) {
      console.error(`\n[Migration] âŒ ${table}: ${error.message}`);
      return {
        table,
        rowsCopied,
        duration: Date.now() - startTime,
        success: false,
        error: error.message
      };
    }
  }

  async verifyMigration(table: string): Promise<{
    table: string;
    sourceCount: number;
    targetCount: number;
    match: boolean;
  }> {
    if (!this.sourcePool || !this.targetPool) {
      throw new Error('Database pools not initialized');
    }

    const sourceCount = await this.getTableRowCount(this.sourcePool, table);
    const targetCount = await this.getTableRowCount(this.targetPool, table);

    return {
      table,
      sourceCount,
      targetCount,
      match: sourceCount === targetCount
    };
  }

  async run(): Promise<MigrationReport> {
    const startTime = new Date();
    const results: MigrationResult[] = [];

    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log('          TBURN ENTERPRISE DATABASE MIGRATION');
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log(`Start Time: ${startTime.toISOString()}`);
    console.log(`Tables to migrate: ${this.config.tables.length}`);
    console.log(`Batch size: ${this.config.batchSize}`);
    console.log(`Dry run: ${this.config.dryRun}`);
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

    try {
      await this.initialize();

      for (const table of this.config.tables) {
        if (this.aborted) break;
        const result = await this.migrateTable(table);
        results.push(result);
      }

      // ê²€ì¦
      console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
      console.log('                    VERIFICATION');
      console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

      for (const table of this.config.tables.slice(0, 10)) {
        const verification = await this.verifyMigration(table);
        const status = verification.match ? 'âœ…' : 'âš ï¸';
        console.log(`${status} ${table}: ${verification.sourceCount} â†’ ${verification.targetCount}`);
      }

    } finally {
      await this.cleanup();
    }

    const endTime = new Date();
    const report: MigrationReport = {
      startTime,
      endTime,
      totalDuration: endTime.getTime() - startTime.getTime(),
      results,
      summary: {
        totalTables: this.config.tables.length,
        successfulTables: results.filter(r => r.success).length,
        failedTables: results.filter(r => !r.success).length,
        totalRowsCopied: results.reduce((sum, r) => sum + r.rowsCopied, 0)
      }
    };

    console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log('                    MIGRATION COMPLETE');
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log(`Duration: ${(report.totalDuration / 1000).toFixed(1)}s`);
    console.log(`Tables: ${report.summary.successfulTables}/${report.summary.totalTables} successful`);
    console.log(`Rows copied: ${report.summary.totalRowsCopied.toLocaleString()}`);
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

    return report;
  }

  abort(): void {
    console.log('[Migration] âš ï¸ Aborting migration...');
    this.aborted = true;
  }

  async cleanup(): Promise<void> {
    if (this.sourcePool) {
      await this.sourcePool.end();
    }
    if (this.targetPool) {
      await this.targetPool.end();
    }
    console.log('[Migration] ğŸ§¹ Database connections closed');
  }
}

// CLI ì‹¤í–‰
async function main() {
  const sourceUrl = process.env.DATABASE_URL;
  const targetUrl = process.env.DATABASE_URL_PROD;

  if (!sourceUrl) {
    console.error('âŒ DATABASE_URL (source) is required');
    process.exit(1);
  }

  if (!targetUrl) {
    console.error('âŒ DATABASE_URL_PROD (target) is required');
    console.error('');
    console.error('To set up production database:');
    console.error('1. Create a new database in Replit Dashboard');
    console.error('2. Set DATABASE_URL_PROD secret with the connection string');
    console.error('3. Run this migration script again');
    process.exit(1);
  }

  const migrator = new EnterpriseDbMigrator({
    sourceUrl,
    targetUrl,
    tables: CORE_TABLES,
    batchSize: parseInt(process.env.MIGRATION_BATCH_SIZE || '100', 10),
    dryRun: process.env.MIGRATION_DRY_RUN === 'true'
  });

  // ì¢…ë£Œ ì‹œê·¸ë„ ì²˜ë¦¬
  process.on('SIGINT', () => {
    migrator.abort();
  });

  process.on('SIGTERM', () => {
    migrator.abort();
  });

  try {
    await migrator.run();
    process.exit(0);
  } catch (error: any) {
    console.error('âŒ Migration failed:', error.message);
    process.exit(1);
  }
}

// ì§ì ‘ ì‹¤í–‰ ì‹œì—ë§Œ main í•¨ìˆ˜ í˜¸ì¶œ (ES module ë°©ì‹)
import { fileURLToPath } from 'url';
const __filename = fileURLToPath(import.meta.url);

// tsxë¡œ ì§ì ‘ ì‹¤í–‰ ì‹œ main í•¨ìˆ˜ í˜¸ì¶œ
main();

export { EnterpriseDbMigrator, CORE_TABLES, MigrationConfig, MigrationReport };
